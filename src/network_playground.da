# type: ignore
from utils import getObjectFromPath
from object_types import MsgType
from logger_util import LOGGER


class NetworkPlayground(process):
    def setup(scenario_executor_pid, number_of_nodes: int, number_of_twins: int, scenario, node_number_to_pid_mapping, pid_to_node_number_mapping, node_to_twin, twin_to_node, config_id, scenario_id):

        LOGGER.np = self
        LOGGER.scenario_executor = scenario_executor_pid

        LOGGER.process_id = "network_playground"
        LOGGER.filename = '../logs/config' + str(config_id) + '/' \
            + '/scenario'+str(scenario_id)+'/' \
            + LOGGER.process_id + ".log"

        self.scenario = scenario
        self.rounds = len(scenario['leaders'])-3
        self.commit_config = dict()
        self.node_number_to_pid_mapping = node_number_to_pid_mapping
        self.done_flag = False
        self.livenessFlag = False
        self.pid_to_node_number_mapping = pid_to_node_number_mapping
        self.scenario_executor_pid = scenario_executor_pid
        # Maintains record of rounds for which timeout msgs dropped for a particular node
        self.node_to_timeout_drop_rounds = dict()

    ##################   Helper functions   ##################

    ''' returns True if node_number present in twin_to_node else return False '''
    def is_twin(node_number):
        return node_number in self.twin_to_node

    ''' returns the twin of node if it exists else None '''
    def get_twin(node_num):
        return self.node_to_twin.get(node_num)

    ''' returns the round number of message based on message type (proposal | vote | timeout) '''
    def get_msg_round(msg, msg_type):
        if msg_type == MsgType.Proposal:
            return msg.block.round
        elif msg_type == MsgType.Vote:
            return msg.vote_info.round
        elif msg_type == MsgType.Timeout:
            return msg.tmo_info.round

    ''' returns partitions for a particular round '''
    def get_partitions_in_round(msg_round):
        return self.scenario["partitions"][msg_round-1]

    ''' returns list of msg types to be dropped within partitions in a round '''
    def get_msg_types_to_drop_in_round(msg_round):
        return self.scenario["message_types"][msg_round-1]

    ''' tells whether msg_type is eligible for intra partition dropping '''
    def to_drop(msg_sender_number, msg_round, idx, msg_type):
        msg_types_to_drop = get_msg_types_to_drop_in_round(msg_round)[idx]

        if msg_type == MsgType.Proposal:
            if "Proposal" in msg_types_to_drop:
                return True

        elif msg_type == MsgType.Timeout:
            if "Timeout" in msg_types_to_drop:

                if msg_sender_number not in self.node_to_timeout_drop_rounds:
                    # Means it has never dropped timeout msgs in this round
                    self.node_to_timeout_drop_rounds[msg_sender_number] = [
                        msg_round]
                    # Update map and return False - to drop this timeout msg
                    return True

                if msg_round in self.node_to_timeout_drop_rounds[msg_sender_number]:
                    # Means it has dropped a timeout msg in this round before
                    # Hence ask to not drop
                    return False

                # Update map to remember that it dropped a timeout msg for this round
                self.node_to_timeout_drop_rounds[msg_sender_number].append(
                    msg_round)
                return True

        elif msg_type == MsgType.Vote:
            if "Voting" in msg_types_to_drop:
                return True

        return False

    ''' get current partition at a particular index in partitions array '''
    def get_partition_at_idx(idx, msg_round, node):
        return self.scenario["partitions"][msg_round-1][idx]

    ''' return index of partition for given round in which node is present '''
    def get_current_partition_index(msg_round, node):
        partitions_in_round = get_partitions_in_round(msg_round)
        for i in range(len(partitions_in_round)):
            if node in partitions_in_round[i]:
                return i
        return -1

    ''' If the node p is a twin, then message should appear as though it was sent by the actual node, and not the twin '''
    def replace_with_twin_if_needed(node):
        actual_sender = node
        if self.is_twin(node):
            actual_sender = self.twin_to_node[node]
        return actual_sender

    ''' sends the msg to the appropriate nodes, attaching sender node in message '''
    def send_to_nodes(msg_name, destination_nodes, msg, sender):
        node_pids = []

        for node_num in destination_nodes:
            node_pids.append(self.node_number_to_pid_mapping.get(node_num))
        if node_pids:
            send((msg_name, msg, sender), to=node_pids)

    ##########################################################

    ##################   Receive Handlers   ##################

    ''' Receive handler for proposal messages '''
    def receive(msg=('Proposal', proposal_msg), from_=msg_sender):
        msg_sender_number = self.pid_to_node_number_mapping[msg_sender]
        msg_round = self.get_msg_round(proposal_msg, MsgType.Proposal)

        LOGGER.log_np_event('Received', 'Proposal', msg_sender_number,
                            {}, msg_round, proposal_msg)

        ''' if msg_round exceeds even the over estimated round, ignore '''
        if msg_round >= self.rounds + 3:
            LOGGER.log_event('Sent', 'Stop Processes', {},
                             self.scenario_executor_pid)
            send(('Stop Processes',), to=self.scenario_executor_pid)
            return

        destination_nodes = set()

        ''' When current round is after self.rounds, there is only one partition with all the nodes '''
        if msg_round > self.rounds:
            # no notion of partitions in this round, i.e. all nodes present in the same partition

            partitions_in_round = self.get_partitions_in_round(msg_round)
            # broadcast messages to all nodes in the system
            for partition in partitions_in_round:
                for node_number in partition:
                    destination_nodes.add(node_number)

        else:
            ''' When msg_round <= rounds, create partitions according to the scenario '''
            # get index of partition in which msg_sender lies
            msg_partition_idx = self.get_current_partition_index(
                msg_round, msg_sender_number)

            # check if msg is eligible for intra partition dropping
            if to_drop(msg_sender_number, msg_round, msg_partition_idx, MsgType.Proposal):
                # drop this message, ignore

                LOGGER.log_np_event('Dropped msg', 'Proposal', msg_sender_number,
                                    destination_nodes, msg_round, proposal_msg)
                return

            partition = self.get_partition_at_idx(
                msg_partition_idx, msg_round, msg_sender)

            for node_number in partition:
                destination_nodes.add(node_number)

        # sender node will be updated if it is a twin
        actual_sender_node = self.replace_with_twin_if_needed(
            msg_sender_number)

        if len(destination_nodes) > 0:

            LOGGER.log_np_event('Sent', 'Proposal', actual_sender_node,
                                destination_nodes, msg_round, proposal_msg)
            self.send_to_nodes('Proposal', destination_nodes,
                               proposal_msg, actual_sender_node)

    ''' Receive handler for vote messages '''
    def receive(msg=('Vote', vote_msg, destination_node_num), from_=msg_sender):

        msg_sender_number = self.pid_to_node_number_mapping[msg_sender]
        msg_round = self.get_msg_round(vote_msg, MsgType.Vote)

        LOGGER.log_np_event('Received', 'Vote', msg_sender_number,
                            destination_node_num, msg_round, vote_msg)

        ''' if msg_round exceeds even the over estimated round, ignore '''
        if msg_round >= self.rounds + 3:

            LOGGER.log_event('Sent', 'Stop Processes', {},
                             self.scenario_executor_pid)
            send(('Stop Processes',), to=self.scenario_executor_pid)
            return

        destination_nodes = set()

        ''' When current round is after self.rounds, there is only one partition with all the nodes '''
        if msg_round > self.rounds:
            # no notion of partitions in this round, i.e. all nodes present in the same partition

            destination_nodes.add(destination_node_num)

            ''' If destination node has twin, then message should be sent to twin as well '''
            if self.get_twin(destination_node_num) is not None:
                destination_nodes.add(self.get_twin(destination_node_num))

        else:
            ''' When msg_round <= rounds, create partitions according to the scenario '''

            # get index of partition in which msg_sender lies
            msg_partition_idx = self.get_current_partition_index(
                msg_round, msg_sender_number)

            # check if msg is eligible for intra partition dropping
            if to_drop(msg_sender_number, msg_round, msg_partition_idx, MsgType.Vote):

                LOGGER.log_np_event('Dropped msg', 'Vote', msg_sender_number,
                                    destination_nodes, msg_round, vote_msg)
                return

            partition = self.get_partition_at_idx(
                msg_partition_idx, msg_round, msg_sender)

            if destination_node_num in partition:
                destination_nodes.add(destination_node_num)

            if self.get_twin(destination_node_num) is not None and self.get_twin(destination_node_num) in partition:
                destination_nodes.add(self.get_twin(destination_node_num))

        # sender node will be updated if it is a twin
        actual_sender_node = self.replace_with_twin_if_needed(
            msg_sender_number)

        if len(destination_nodes) > 0:

            LOGGER.log_np_event('Sent', 'Vote', msg_sender_number,
                                destination_nodes, msg_round, vote_msg)

            self.send_to_nodes('Vote', destination_nodes,
                               vote_msg, actual_sender_node)

    ''' Receive handler for timeout messages '''
    def receive(msg=('Timeout', timeout_msg), from_=msg_sender):

        msg_sender_number = self.pid_to_node_number_mapping[msg_sender]

        msg_round = self.get_msg_round(timeout_msg, MsgType.Timeout)

        LOGGER.log_np_event('Received', 'Timeout', msg_sender_number,
                            {}, msg_round, timeout_msg)

        ''' if msg_round exceeds even the over estimated round, ignore '''
        if msg_round >= self.rounds + 3:

            LOGGER.log_event('Sent', 'Stop Processes', {},
                             self.scenario_executor_pid)
            send(('Stop Processes',), to=self.scenario_executor_pid)
            return

        destination_nodes = set()
        ''' When current round is after self.rounds, there is only one partition with all the nodes '''
        if msg_round > self.rounds:
            # no notion of partitions in this round, i.e. all nodes present in the same partition
            partitions_in_round = self.get_partitions_in_round(msg_round)

            # broadcast messages to all nodes in the system
            for partition in partitions_in_round:
                for node_number in partition:
                    destination_nodes.add(node_number)

        else:
            ''' When msg_round <= rounds, create partitions according to the scenario '''
            # get index of partition in which msg_sender lies ---  using get_current_partition_index
            msg_partition_idx = self.get_current_partition_index(
                msg_round, msg_sender_number)
            # check if msg is eligible for intra partition dropping
            if to_drop(msg_sender_number, msg_round, msg_partition_idx, MsgType.Timeout):
                # drop this message, ignore
                LOGGER.log_np_event('Dropped msg', 'Timeout', msg_sender_number,
                                    destination_nodes, msg_round, timeout_msg)
                return

            partition = self.get_partition_at_idx(
                msg_partition_idx, msg_round, msg_sender)
            for node_number in partition:
                destination_nodes.add(node_number)

        # sender node will be updated if it is a twin
        actual_sender_node = self.replace_with_twin_if_needed(
            msg_sender_number)

        if len(destination_nodes) > 0:

            LOGGER.log_np_event('Sent', 'Timeout', actual_sender_node,
                                destination_nodes, msg_round, timeout_msg)
            self.send_to_nodes('Timeout', destination_nodes,
                               timeout_msg, actual_sender_node)

    ''' Receive handler for requesting sync up by a validator
        Broadcasts this request to all other validators which help the node to sync up
        past_round <- from, current_round <- to'''
    def receive(msg=('Sync up required', past_round, current_round), from_=msg_sender):
        LOGGER.log_np_event('Received', 'Sync up required', msg_sender,
                            {}, "from = "+str(past_round), None, "to = "+str(current_round))
        destination_nodes = list(self.pid_to_node_number_mapping.keys())
        destination_nodes.remove(msg_sender)

        send(('Sync up needed', past_round, current_round, msg_sender
              ), to=destination_nodes)
        LOGGER.log_np_event('Sent', 'Sync up needed', msg_sender,
                            destination_nodes, "from = "+str(past_round), None, "to = "+str(current_round))

        ##########################################################

    ''' Recieve handlers for messages from validators containing information to be sent to lagging node'''
    ''' proposals_map, sync_map <- Required data'''
    ''' Requester <-  lagging node'''
    def receive(msg=("Sync up proposals", proposals_map, sync_map, requester),
                from_=msg_sender):

        LOGGER.log_np_event('Received', 'Sync up proposals', msg_sender,
                            {}, None, None, "lagging_node = " + str(requester), "proposals_map = " + str(proposals_map), "sync_map = " + str(sync_map))
        send(("Sync up proposals", proposals_map, sync_map, msg_sender),
             to=requester)
        LOGGER.log_np_event('Sent', 'Sync up proposals', msg_sender,
                            "lagging_node = " + str(requester), None, None, "proposals_map = " + str(proposals_map), "sync_map = " + str(sync_map))

    ''' Receive handler for message from lagging_node informing others that its done syncing up
        Broadcasts message to others nodes informing that lagging_node is done syncing up'''
    def receive(msg=("Done sync up"), from_=p):
        LOGGER.log_np_event('Received', 'Done sync up', p,
                            {}, None, None)
        destination_nodes = list(self.pid_to_node_number_mapping.keys())
        destination_nodes.remove(p)
        send(("Done sync up", p), to=destination_nodes)
        LOGGER.log_np_event('Sent', 'Done sync up', p,
                            destination_nodes, None, None)

    '''Receive handler for message from a node which detects a lagging_node
        Forwards to the lagging node the required rounds it needs to sync up
        to_round <- round till which lagging_node should sync up
        '''
    def receive(msg=("kindly sync up", to_round, behind_node), from_=msg_sender):
        LOGGER.log_np_event('Received', 'kindly sync up', msg_sender,
                            {}, None, " to = "+str(to_round), behind_node)
        destination = []
        destination.append(self.node_number_to_pid_mapping[behind_node])
        if behind_node in self.node_to_twin:
            destination.append(
                self.node_number_to_pid_mapping[self.node_to_twin[behind_node]])

        send(("kindly sync up", to_round), to=destination)
        LOGGER.log_np_event('Sent', 'kindly sync up', msg_sender,
                            destination, None, " to = "+str(to_round), behind_node)

    ''' Receive handler to inform network playground that liveness is upheld'''
    def receive(msg=('TC or QC generated'), from_=v):
        LOGGER.log_np_event('Received', 'TC or QC generated', v,
                            None)
        self.livenessFlag = True
        LOGGER.log_action('Set livenessFlag to:', self.livenessFlag)

    ''' Receive handler to receive commit configs from validators for safety testing.
    Forwards these configs to the scenario executor once all validators have returned them
    Exits network playground once this is forwarded'''
    def receive(msg=('Commit config', commit_config), from_=v):
        LOGGER.log_np_event('Received', 'Commit config', v,
                            None, None, commit_config)
        self.commit_config[v] = commit_config
        if len(self.commit_config) == len(self.pid_to_node_number_mapping):
            # output("Final ", self.commit_config)
            send(("forward commit config", self.commit_config), to=parent())
            LOGGER.log_np_event('Sent', 'forward commit config', v,
                                parent(), None, self.commit_config)
            exit()

    def run():
        while not self.done_flag:
            if await(self.livenessFlag):
                LOGGER.log_np_event(
                    'Flag changed', 'self.livenessFlag', None, None, None)
                self.livenessFlag = False
                LOGGER.log_action('Set livenessFlag to:', self.livenessFlag)

            elif timeout(30):
                send(('Stop Processes',), to=self.scenario_executor_pid)
                LOGGER.log_action(" Timed out ", None)
                LOGGER.log_np_event('Sent', 'Stop Processes',
                                    self.scenario_executor_pid, None, None)
                LOGGER.log_action(
                    " ******************** Liveness Violated ******************** ", None)

        exit()
